server:
  enabled: true

  replicas: 1

  updateStrategy:
    type: RollingUpdate

  image:
    repository: rancher/k3s
    tag: v1.19.4-k3s1
    pullPolicy: Always

  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 10s

  service:
    enabled: true

  serviceNodeport:
    enabled: true
    portApiServer: 30443

  persistentVolume:
    enabled:
      false
    size: 100Mi
    mountPath: /output

  emptyDir:
    sizeLimit: ""

kubestatemetrics:
  standalone:
    enabled: false

  sidecar:
    enabled: true

  replicas: 1

  image:
    repository: quay.io/coreos/kube-state-metrics
    tag: v1.9.7
    pullPolicy: Always

  ## Node labels for pod assignment
  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
  nodeSelector: {}

  ## Affinity settings for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  affinity: {}

  ## Tolerations for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  ## Assign a PriorityClassName to pods if set
  # priorityClassName: ""

  serviceAccount:
    # Specifies whether a ServiceAccount should be created, require rbac true
    create: false
    # The name of the ServiceAccount to use.
    # If not set and create is true, a name is generated using the fullname template
    name:
    # Reference to one or more secrets to be used when pulling images
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    imagePullSecrets: []

  ## ApiServer URL
  # apiserver: ""

  ## kubeconfig
  kubeconfig: /kubeconfig/kubeconfig.yaml

  # Available collectors for kube-state-metrics. By default all available
  # collectors are enabled.
  collectors:
    certificatesigningrequests: true
    configmaps: true
    cronjobs: true
    daemonsets: true
    deployments: true
    endpoints: true
    horizontalpodautoscalers: true
    ingresses: true
    jobs: true
    limitranges: true
    mutatingwebhookconfigurations: false
    namespaces: true
    networkpolicies: false
    nodes: true
    persistentvolumeclaims: true
    persistentvolumes: true
    poddisruptionbudgets: true
    pods: true
    replicasets: true
    replicationcontrollers: true
    resourcequotas: true
    secrets: true
    services: true
    statefulsets: true
    storageclasses: true
    validatingwebhookconfigurations: false
    verticalpodautoscalers: false
    volumeattachements: false

  # Namespace to be enabled for collecting resources. By default all namespaces are collected.
  # namespace: ""

  securityContext:
    enabled: true
    runAsUser: 65534
    fsGroup: 65534

#
# cilium part
#

pprof:
  # -- Enable Go pprof debugging
  enabled: false

# -- Configure prometheus metrics on the configured port at /metrics
prometheus:
  enabled: false

debug:
  # -- Enable debug logging
  enabled: false
  # verbose:

# -- Configure the eBPF-based ip-masq-agent
ipMasqAgent:
  enabled: false

ipv4:
  # -- Enable IPv4 support.
  enabled: true

ipv6:
  # -- Enable IPv6 support.
  enabled: false

cni:
  # -- Install the CNI configuration and binary files into the filesystem.
  install: false

  # -- Configure chaining on top of other CNI plugins. Possible values:
  #  - none
  #  - generic-veth
  #  - aws-cni
  #  - portmap
  chainingMode: none

cluster:
  # -- Name of the cluster. Only required for Cluster Mesh.
  name: default
  # -- (int) Unique ID of the cluster. Must be unique across all connected
  # clusters and in the range of 1 to 255. Only required for Cluster Mesh.
  id:

encryption:
  # -- Enable transparent network encryption.
  enabled: false

# -- Configure maglev consistent hashing
maglev: {}

# -- Configure Istio proxy options.
proxy:
  prometheus:
    port: "9095"
  # -- Regular expression matching compatible Istio sidecar istio-proxy
  # container image names
  sidecarImageRegex: "cilium/istio_proxy"

# -- Configure image pull secrets for pulling container images
imagePullSecrets:
# - name: "image-pull-secret"

# kubeConfigPath: ~/.kube/config

azure:
  # -- Enable Azure integration
  enabled: false

gke:
  # -- Enable Google Kubernetes Engine integration
  enabled: false

# flannel is the flannel specific configuration
flannel:
  # enabled enables the flannel integration
  enabled: false

bpf:
  clockProbe: false

  # -- Force the cilium-agent DaemonSet to wait in an initContainer until the
  # eBPF filesystem has been mounted.
  waitForMount: false

  # -- Enables pre-allocation of eBPF map values. This increases
  # memory usage but can reduce latency.
  preallocateMaps: false

  # -- Configure the maximum number of entries in the TCP connection tracking
  # table.
  ctTcpMax: 524288

  # -- Configure the maximum number of entries for the non-TCP connection
  # tracking table.
  ctAnyMax: 262144

  # -- Configure the maximum number of service entries in the
  # load balancer maps.
  lbMapMax: 65536

  # -- Configure the maximum number of entries for the NAT table.
  # natMax: 524288

  # -- Configure the maximum number of entries for the neighbor table.
  # neighMax: 524288

  # -- Configure the maximum number of entries in endpoint policy map.
  # (per endpoint)
  policyMapMax: 16384

  # -- Configure auto-sizing for all BPF maps based on available memory.
  # ref: https://docs.cilium.io/en/v1.9/concepts/ebpf/maps/#ebpf-maps
  #mapDynamicSizeRatio: 0.0025

  # -- Configure the level of aggregation for monitor notifications.
  # Valid options are none, low, medium, maximum
  monitorAggregation: medium

  # -- Configure the typical time between monitor notifications for
  # active connections.
  monitorInterval: "5s"

  # -- Configure which TCP flags trigger notifications when seen for the
  # first time in a connection.
  monitorFlags: "all"

  # -- Enable native IP masquerade support in eBPF
  #masquerade: true

  # -- Configure whether direct routing mode should route traffic via
  # host stack (true) or directly and more efficiently out of BPF (false) if
  # the kernel supports it. The latter has the implication that it will also
  # bypass netfilter in the host namespace.
  #hostRouting: true

  # -- Configure the eBPF-based TPROXY to reduce reliance on iptables rules
  # for implementing Layer 7 policy.
  # tproxy: true

etcd:
  # -- Enable etcd mode for the agent.
  enabled: false

  # -- If etcd is behind a k8s service set this option to true so that Cilium
  # does the service translation automatically without requiring a DNS to be
  # running.
  k8sService: false

# -- Install the cilium agent resources.
agent: false

preflight:
  # -- Enable Cilium pre-flight resources (required for upgrade)
  enabled: false

# -- Configure BPF socket operations configuration
sockops:
  # enabled enables installation of socket options acceleration.
  enabled: false

# -- Configure Kubernetes specific configuration
k8s: {}
  # -- requireIPv4PodCIDR enables waiting for Kubernetes to provide the PodCIDR
  # range via the Kubernetes node resource
  # requireIPv4PodCIDR: false

  # -- requireIPv6PodCIDR enables waiting for Kubernetes to provide the PodCIDR
  # range via the Kubernetes node resource
# requireIPv46PodCIDR: false

# TODO: Add documentation
endpointHealthChecking:
  enabled: true

endpointRoutes:
  # -- Enable use of per endpoint routes instead of routing via
  # the cilium_host interface.
  enabled: false

ipam:
  # -- Configure IP Address Management mode.
  # ref: https://docs.cilium.io/en/stable/concepts/networking/ipam/
  mode: "cluster-pool"
  operator:
    # -- IPv4 CIDR range to delegate to individual nodes for IPAM.
    clusterPoolIPv4PodCIDR: "10.0.0.0/8"
    # -- IPv4 CIDR mask size to delegate to individual nodes for IPAM.
    clusterPoolIPv4MaskSize: 24
    # -- IPv6 CIDR range to delegate to individual nodes for IPAM.
    clusterPoolIPv6PodCIDR: "fd00::/104"
    # -- IPv6 CIDR mask size to delegate to individual nodes for IPAM.
    clusterPoolIPv6MaskSize: 120

# -- Define serviceAccount names for components.
# @default -- Component's fully qualified name.
serviceAccounts:
  operator:
    create: true
    annotations: {}

operator:
  # -- Enable the cilium-operator component (required).
  enabled: true

  # -- cilium-operator image.
  image:
    repository: quay.io/cilium/operator
    tag: latest
    pullPolicy: Always

  # -- Number of replicas to run for the cilium-operator deployment
  replicas: 2

  # -- cilium-operator priorityClassName
  priorityClassName: ""

  # -- cilium-operator update strategy
  updateStrategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate

  # -- cilium-operator affinity
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: io.cilium/app
                operator: In
                values:
                  - operator
          topologyKey: kubernetes.io/hostname


  # -- Additional cilium-etcd-operator container arguments
  #
  extraArgs: {}

  extraEnv: {}

  # -- Additional InitContainers to initialize the pod
  #
  extraInitContainers: []

  # -- Additional cilium-operator hostPath mounts
  extraHostPathMounts: []
    # - name: host-mnt-data
    #   mountPath: /host/mnt/data
    #   hostPath: /mnt/data
    #   hostPathType: Directory
    #   readOnly: true
  #   mountPropagation: HostToContainer

  extraConfigmapMounts: []
    # - name: certs-configmap
    #   mountPath: /certs
    #   configMap: certs-configmap
  #   readOnly: true

  # -- Node tolerations for cilium-operator scheduling to nodes with taints
  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
  #
  tolerations:
    - operator: Exists
      # - key: "key"
      #   operator: "Equal|Exists"
      #   value: "value"
      #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

  # -- Node labels for cilium-operator pod assignment
  # ref: https://kubernetes.io/docs/user-guide/node-selection/
  #
  nodeSelector: {}

  # -- Annotations to be added to cilium-operator pods
  #
  podAnnotations: {}

  # -- Labels to be added to cilium-operator pods
  #
  podLabels: {}

  # -- PodDisruptionBudget settings
  # ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  #
  podDisruptionBudget:
    enabled: false
    maxUnavailable: 1

  # -- cilium-operator resource limits & requests
  # ref: https://kubernetes.io/docs/user-guide/compute-resources/
  #
  resources: {}
    # limits:
    #   cpu: 1000m
    #   memory: 1Gi
    # requests:
    #   cpu: 100m
  #   memory: 128Mi

  # -- Security context to be added to cilium-operator pods
  #
  securityContext: {}
  # runAsUser: 0

  endpointGCInterval: "5m0s"
  identityGCInterval: "15m0s"
  identityHeartbeatTimeout: "30m0s"

  # -- Enable prometheus metrics for cilium-operator on the configured port at
  # /metrics
  prometheus:
    enabled: true
    port: 6942
    serviceMonitor:
      # -- Enable service monitors.
      # This requires the prometheus CRDs to be available (see https://github.com/prometheus-operator/prometheus-operator/blob/master/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml)
      ##
      enabled: true

